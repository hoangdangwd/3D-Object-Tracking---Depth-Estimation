import pandas as pd
from pathlib import Path
import numpy as np


def check_csv_structure(csv_path):
    """
    Ki·ªÉm tra c·∫•u tr√∫c v√† n·ªôi dung c·ªßa CSV file
    """
    try:
        df = pd.read_csv(csv_path)
        
        issues = []
        warnings = []
        
        # Ki·ªÉm tra columns
        required_cols = ['sample_name', 'MAE_Detection', 'MAE_Segmentation', 
                        'Time_Detection_ms', 'Time_Segmentation_ms']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            issues.append(f"‚ùå Thi·∫øu c·ªôt: {', '.join(missing_cols)}")
            return None, issues, warnings
        
        # Ki·ªÉm tra s·ªë l∆∞·ª£ng records
        if len(df) == 0:
            issues.append("‚ùå File r·ªóng - kh√¥ng c√≥ d·ªØ li·ªáu")
            return None, issues, warnings
        
        # Ki·ªÉm tra missing values
        for col in required_cols:
            missing_count = df[col].isna().sum()
            if missing_count > 0:
                warnings.append(f"‚ö†Ô∏è  C·ªôt '{col}': {missing_count} gi√° tr·ªã missing")
        
        # Ki·ªÉm tra gi√° tr·ªã √¢m
        if (df['MAE_Detection'] < 0).any():
            issues.append("‚ùå MAE_Detection c√≥ gi√° tr·ªã √¢m")
        if (df['MAE_Segmentation'] < 0).any():
            issues.append("‚ùå MAE_Segmentation c√≥ gi√° tr·ªã √¢m")
        if (df['Time_Detection_ms'] < 0).any():
            issues.append("‚ùå Time_Detection_ms c√≥ gi√° tr·ªã √¢m")
        if (df['Time_Segmentation_ms'] < 0).any():
            issues.append("‚ùå Time_Segmentation_ms c√≥ gi√° tr·ªã √¢m")
        
        # Ki·ªÉm tra gi√° tr·ªã v√¥ l√Ω
        if (df['MAE_Detection'] > 1000).any():
            count = (df['MAE_Detection'] > 1000).sum()
            warnings.append(f"‚ö†Ô∏è  MAE_Detection: {count} gi√° tr·ªã > 1000m (c√≥ th·ªÉ sai)")
        
        if (df['MAE_Segmentation'] > 1000).any():
            count = (df['MAE_Segmentation'] > 1000).sum()
            warnings.append(f"‚ö†Ô∏è  MAE_Segmentation: {count} gi√° tr·ªã > 1000m (c√≥ th·ªÉ sai)")
        
        if (df['Time_Detection_ms'] > 10000).any():
            count = (df['Time_Detection_ms'] > 10000).sum()
            warnings.append(f"‚ö†Ô∏è  Time_Detection_ms: {count} gi√° tr·ªã > 10s (qu√° ch·∫≠m)")
        
        # Ki·ªÉm tra inf values
        for col in ['MAE_Detection', 'MAE_Segmentation']:
            inf_count = np.isinf(df[col]).sum()
            if inf_count > 0:
                issues.append(f"‚ùå {col}: {inf_count} gi√° tr·ªã infinity")
        
        return df, issues, warnings
        
    except Exception as e:
        return None, [f"‚ùå L·ªói ƒë·ªçc file: {str(e)}"], []


def analyze_depth_results(result_dir):
    """
    Ph√¢n t√≠ch t·∫•t c·∫£ 4 file CSV results
    """
    result_dir = Path(result_dir)
    
    classes = ['motorblue', 'motorwhite', 'person', 'pot']
    
    print("\n" + "="*80)
    print("KI·ªÇM TRA K·∫æT QU·∫¢ DEPTH ESTIMATION")
    print("="*80)
    
    all_results = {}
    
    for cls in classes:
        csv_path = result_dir / f"depth_results_{cls}.csv"
        
        print(f"\n{'='*80}")
        print(f"üìä CLASS: {cls.upper()}")
        print(f"{'='*80}")
        print(f"File: {csv_path.name}")
        
        if not csv_path.exists():
            print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {csv_path}")
            continue
        
        df, issues, warnings = check_csv_structure(csv_path)
        
        if df is None:
            print("\n‚ùå KI·ªÇM TRA C·∫§U TR√öC:")
            for issue in issues:
                print(f"  {issue}")
            continue
        
        # In issues v√† warnings
        if issues:
            print("\n‚ùå L·ªñI:")
            for issue in issues:
                print(f"  {issue}")
        
        if warnings:
            print("\n‚ö†Ô∏è  C·∫¢NH B√ÅO:")
            for warning in warnings:
                print(f"  {warning}")
        
        if not issues and not warnings:
            print("\n‚úÖ C·∫§U TR√öC: OK")
        
        # Th·ªëng k√™
        print("\nüìà TH·ªêNG K√ä:")
        print(f"  ‚Ä¢ S·ªë m·∫´u: {len(df)}")
        
        print(f"\n  üìè MAE DETECTION (meters):")
        print(f"    ‚Ä¢ Mean: {df['MAE_Detection'].mean():.4f}m")
        print(f"    ‚Ä¢ Median: {df['MAE_Detection'].median():.4f}m")
        print(f"    ‚Ä¢ Std: {df['MAE_Detection'].std():.4f}m")
        print(f"    ‚Ä¢ Min: {df['MAE_Detection'].min():.4f}m")
        print(f"    ‚Ä¢ Max: {df['MAE_Detection'].max():.4f}m")
        print(f"    ‚Ä¢ 25%: {df['MAE_Detection'].quantile(0.25):.4f}m")
        print(f"    ‚Ä¢ 75%: {df['MAE_Detection'].quantile(0.75):.4f}m")
        
        print(f"\n  üé® MAE SEGMENTATION (meters):")
        print(f"    ‚Ä¢ Mean: {df['MAE_Segmentation'].mean():.4f}m")
        print(f"    ‚Ä¢ Median: {df['MAE_Segmentation'].median():.4f}m")
        print(f"    ‚Ä¢ Std: {df['MAE_Segmentation'].std():.4f}m")
        print(f"    ‚Ä¢ Min: {df['MAE_Segmentation'].min():.4f}m")
        print(f"    ‚Ä¢ Max: {df['MAE_Segmentation'].max():.4f}m")
        print(f"    ‚Ä¢ 25%: {df['MAE_Segmentation'].quantile(0.25):.4f}m")
        print(f"    ‚Ä¢ 75%: {df['MAE_Segmentation'].quantile(0.75):.4f}m")
        
        print(f"\n  ‚è±Ô∏è  TH·ªúI GIAN DETECTION (ms):")
        print(f"    ‚Ä¢ Mean: {df['Time_Detection_ms'].mean():.2f}ms")
        print(f"    ‚Ä¢ Median: {df['Time_Detection_ms'].median():.2f}ms")
        print(f"    ‚Ä¢ Min: {df['Time_Detection_ms'].min():.2f}ms")
        print(f"    ‚Ä¢ Max: {df['Time_Detection_ms'].max():.2f}ms")
        
        print(f"\n  ‚è±Ô∏è  TH·ªúI GIAN SEGMENTATION (ms):")
        print(f"    ‚Ä¢ Mean: {df['Time_Segmentation_ms'].mean():.2f}ms")
        print(f"    ‚Ä¢ Median: {df['Time_Segmentation_ms'].median():.2f}ms")
        print(f"    ‚Ä¢ Min: {df['Time_Segmentation_ms'].min():.2f}ms")
        print(f"    ‚Ä¢ Max: {df['Time_Segmentation_ms'].max():.2f}ms")
        
        # So s√°nh Detection vs Segmentation
        better_detection = (df['MAE_Detection'] < df['MAE_Segmentation']).sum()
        better_segmentation = (df['MAE_Segmentation'] < df['MAE_Detection']).sum()
        equal = (df['MAE_Detection'] == df['MAE_Segmentation']).sum()
        
        print(f"\n  üÜö SO S√ÅNH DETECTION vs SEGMENTATION:")
        print(f"    ‚Ä¢ Detection t·ªët h∆°n: {better_detection} m·∫´u ({better_detection/len(df)*100:.1f}%)")
        print(f"    ‚Ä¢ Segmentation t·ªët h∆°n: {better_segmentation} m·∫´u ({better_segmentation/len(df)*100:.1f}%)")
        print(f"    ‚Ä¢ B·∫±ng nhau: {equal} m·∫´u ({equal/len(df)*100:.1f}%)")
        
        # Top 5 m·∫´u t·ªët nh·∫•t v√† t·ªá nh·∫•t
        print(f"\n  üèÜ TOP 5 M·∫™U T·ªêT NH·∫§T (MAE Detection):")
        best_samples = df.nsmallest(5, 'MAE_Detection')[['sample_name', 'MAE_Detection', 'MAE_Segmentation']]
        for idx, row in best_samples.iterrows():
            print(f"    ‚Ä¢ {row['sample_name']}: Det={row['MAE_Detection']:.4f}m, Seg={row['MAE_Segmentation']:.4f}m")
        
        print(f"\n  ‚ö†Ô∏è  TOP 5 M·∫™U T·ªÜ NH·∫§T (MAE Detection):")
        worst_samples = df.nlargest(5, 'MAE_Detection')[['sample_name', 'MAE_Detection', 'MAE_Segmentation']]
        for idx, row in worst_samples.iterrows():
            print(f"    ‚Ä¢ {row['sample_name']}: Det={row['MAE_Detection']:.4f}m, Seg={row['MAE_Segmentation']:.4f}m")
        
        # L∆∞u v√†o dict
        all_results[cls] = df
    
    # So s√°nh gi·ªØa c√°c classes
    print("\n" + "="*80)
    print("SO S√ÅNH GI·ªÆA C√ÅC CLASSES")
    print("="*80)
    
    if all_results:
        comparison_data = []
        for cls, df in all_results.items():
            comparison_data.append({
                'Class': cls,
                'Samples': len(df),
                'MAE_Det_Mean': df['MAE_Detection'].mean(),
                'MAE_Seg_Mean': df['MAE_Segmentation'].mean(),
                'Time_Det_Mean': df['Time_Detection_ms'].mean(),
                'Time_Seg_Mean': df['Time_Segmentation_ms'].mean()
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        
        print("\nüìä B·∫£ng so s√°nh:")
        print(comparison_df.to_string(index=False))
        
        # T√¨m class t·ªët nh·∫•t
        best_det_cls = comparison_df.loc[comparison_df['MAE_Det_Mean'].idxmin(), 'Class']
        best_seg_cls = comparison_df.loc[comparison_df['MAE_Seg_Mean'].idxmin(), 'Class']
        fastest_det_cls = comparison_df.loc[comparison_df['Time_Det_Mean'].idxmin(), 'Class']
        
        print(f"\nüèÜ K·∫æT QU·∫¢ T·ªêT NH·∫§T:")
        print(f"  ‚Ä¢ MAE Detection th·∫•p nh·∫•t: {best_det_cls} ({comparison_df[comparison_df['Class']==best_det_cls]['MAE_Det_Mean'].values[0]:.4f}m)")
        print(f"  ‚Ä¢ MAE Segmentation th·∫•p nh·∫•t: {best_seg_cls} ({comparison_df[comparison_df['Class']==best_seg_cls]['MAE_Seg_Mean'].values[0]:.4f}m)")
        print(f"  ‚Ä¢ X·ª≠ l√Ω nhanh nh·∫•t: {fastest_det_cls} ({comparison_df[comparison_df['Class']==fastest_det_cls]['Time_Det_Mean'].values[0]:.2f}ms)")
    
    # ƒê√°nh gi√° t·ªïng quan
    print("\n" + "="*80)
    print("ƒê√ÅNH GI√Å T·ªîNG QUAN")
    print("="*80)
    
    if all_results:
        # T√≠nh MAE trung b√¨nh c·ªßa t·∫•t c·∫£
        all_mae_det = []
        all_mae_seg = []
        for df in all_results.values():
            all_mae_det.extend(df['MAE_Detection'].tolist())
            all_mae_seg.extend(df['MAE_Segmentation'].tolist())
        
        avg_mae_det = np.mean(all_mae_det)
        avg_mae_seg = np.mean(all_mae_seg)
        
        print(f"\nüìè MAE TRUNG B√åNH TO√ÄN B·ªò DATASET:")
        print(f"  ‚Ä¢ Detection: {avg_mae_det:.4f}m")
        print(f"  ‚Ä¢ Segmentation: {avg_mae_seg:.4f}m")
        
        # ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng
        print(f"\nüíØ ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG:")
        
        if avg_mae_det < 1.0:
            print(f"  ‚úÖ Detection: XU·∫§T S·∫ÆC (MAE < 1m)")
        elif avg_mae_det < 2.0:
            print(f"  ‚úÖ Detection: T·ªêT (MAE 1-2m)")
        elif avg_mae_det < 5.0:
            print(f"  ‚ö†Ô∏è  Detection: TRUNG B√åNH (MAE 2-5m)")
        else:
            print(f"  ‚ùå Detection: K√âM (MAE > 5m)")
        
        if avg_mae_seg < 1.0:
            print(f"  ‚úÖ Segmentation: XU·∫§T S·∫ÆC (MAE < 1m)")
        elif avg_mae_seg < 2.0:
            print(f"  ‚úÖ Segmentation: T·ªêT (MAE 1-2m)")
        elif avg_mae_seg < 5.0:
            print(f"  ‚ö†Ô∏è  Segmentation: TRUNG B√åNH (MAE 2-5m)")
        else:
            print(f"  ‚ùå Segmentation: K√âM (MAE > 5m)")
        
        # Khuy·∫øn ngh·ªã
        print(f"\nüí° KHUY·∫æN NGH·ªä:")
        if avg_mae_seg < avg_mae_det:
            print(f"  ‚Ä¢ Segmentation cho k·∫øt qu·∫£ t·ªët h∆°n Detection")
            print(f"  ‚Ä¢ N√™n s·ª≠ d·ª•ng Segmentation labels cho depth estimation")
        else:
            print(f"  ‚Ä¢ Detection cho k·∫øt qu·∫£ t·ªët h∆°n Segmentation")
            print(f"  ‚Ä¢ Detection nhanh h∆°n, ph√π h·ª£p cho real-time")
        
        print(f"\n  ‚Ä¢ N·∫øu MAE cao: Xem x√©t c·∫£i thi·ªán calibration ho·∫∑c th·ª≠ model depth kh√°c")
        print(f"  ‚Ä¢ Ki·ªÉm tra c√°c m·∫´u t·ªá nh·∫•t ƒë·ªÉ hi·ªÉu nguy√™n nh√¢n l·ªói")
    
    print("\n" + "="*80)


def main():
    result_dir = Path("data/output/depth_estimation_results")
    
    if not result_dir.exists():
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {result_dir}")
        print(f"   Vui l√≤ng ch·∫°y depth_estimation_dataset.py tr∆∞·ªõc!")
        return
    
    analyze_depth_results(result_dir)


if __name__ == "__main__":
    main()
