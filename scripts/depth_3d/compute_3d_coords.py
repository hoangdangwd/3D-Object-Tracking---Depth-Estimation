"""
Script: compute_3d_coords.py (renamed from toaDo.py)
Description: TÃ­nh toÃ¡n tá»a Ä‘á»™ 3D cá»§a cÃ¡c Ä‘iá»ƒm trong áº£nh dá»±a trÃªn:
             - Ma tráº­n intrinsic camera (K)
             - Depth map tá»« MiDaS
             - Äiá»ƒm chuáº©n cÃ³ khoáº£ng cÃ¡ch thá»±c Ä‘Ã£ biáº¿t

Usage:
    python compute_3d_coords.py

Author: CoTracker Extended
Date: 2026-02-03
"""

import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os

# ====== 1. Cáº¥u hÃ¬nh ======
IMG_PATH = "../../data/cache/frames/frame_0077.png"

# Ma tráº­n intrinsic camera K (tá»« calibration)
K = np.array([
    [827.8, 0, 647.73],
    [0, 829.45, 466.9],
    [0, 0, 1]
])
K_inv = np.linalg.inv(K)

# CÃ¡c Ä‘iá»ƒm cáº§n tÃ­nh toáº¡ Ä‘á»™ 3D
points_uv = np.array([
    [1691., 905.],
    [1646., 850.],
    [1674., 761.]
], dtype=np.float32)

# Äiá»ƒm chuáº©n (reference point) cÃ³ khoáº£ng cÃ¡ch thá»±c Ä‘Ã£ biáº¿t
reference_u, reference_v = 250, 750
Z_true_m = 0.76  # Khoáº£ng cÃ¡ch thá»±c táº¡i Ä‘iá»ƒm chuáº©n (mÃ©t)

# ====== 2. Kiá»ƒm tra file tá»“n táº¡i ======
if not os.path.exists(IMG_PATH):
    print(f"âŒ KhÃ´ng tÃ¬m tháº¥y áº£nh: {IMG_PATH}")
    print("ğŸ’¡ HÃ£y cháº¡y save_frame.py hoáº·c cáº­p nháº­t IMG_PATH")
    exit()

# ====== 3. Táº£i MiDaS model ======
print("ğŸ”„ Äang táº£i MiDaS model...")
midas = torch.hub.load("intel-isl/MiDaS", "DPT_Large", trust_repo=True)
midas.eval()

midas_transforms = torch.hub.load("intel-isl/MiDaS", "transforms", trust_repo=True)
transform = midas_transforms.dpt_transform

# ====== 4. Äá»c vÃ  xá»­ lÃ½ áº£nh ======
print(f"ğŸ“¸ Äá»c áº£nh: {os.path.basename(IMG_PATH)}")
img = cv2.imread(IMG_PATH)
if img is None:
    raise FileNotFoundError(f"âŒ KhÃ´ng thá»ƒ Ä‘á»c áº£nh táº¡i: {IMG_PATH}")

img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
H, W = img.shape[:2]
print(f"ğŸ“ KÃ­ch thÆ°á»›c áº£nh: {W}x{H}")

# Transform áº£nh cho MiDaS
input_transformed = transform(img_rgb)
input_tensor = input_transformed["image"] if isinstance(input_transformed, dict) else input_transformed
if input_tensor.dim() == 3:
    input_tensor = input_tensor.unsqueeze(0)

# ====== 5. Dá»± Ä‘oÃ¡n depth map ======
print("ğŸ§® Äang Æ°á»›c lÆ°á»£ng depth map...")
with torch.no_grad():
    prediction = midas(input_tensor)
    prediction = torch.nn.functional.interpolate(
        prediction.unsqueeze(1),
        size=img.shape[:2],
        mode="bicubic",
        align_corners=False,
    ).squeeze()

depth_raw = prediction.cpu().numpy()

# ====== 6. Chuyá»ƒn Ä‘á»•i vÃ  scale depth ======
# MiDaS tráº£ vá» disparity, Ä‘áº£o ngÆ°á»£c Ä‘á»ƒ cÃ³ depth
depth_inv = 1.0 / (depth_raw + 1e-6)

# Láº¥y depth táº¡i Ä‘iá»ƒm chuáº©n
Z_midas_ref = depth_inv[int(reference_v), int(reference_u)]

# TÃ­nh há»‡ sá»‘ scale Ä‘á»ƒ chuyá»ƒn vá» Ä‘Æ¡n vá»‹ mÃ©t thá»±c
scale = Z_true_m / Z_midas_ref
depth_real = depth_inv * scale

print(f"âš–ï¸ Há»‡ sá»‘ scale: {scale:.4f}")
print(f"ğŸ“ Depth táº¡i Ä‘iá»ƒm chuáº©n ({reference_u}, {reference_v}): {Z_true_m} m")

# ====== 7. TÃ­nh toáº¡ Ä‘á»™ 3D (tuyá»‡t Ä‘á»‘i) ======
print("\n" + "="*60)
print("ğŸ“ Tá»ŒA Äá»˜ 3D (há»‡ tá»a Ä‘á»™ camera)")
print("="*60)

results_3d = []

for idx, (u, v) in enumerate(points_uv):
    # Láº¥y Ä‘á»™ sÃ¢u táº¡i pixel (u, v)
    Z = depth_real[int(v), int(u)]
    
    # CÃ´ng thá»©c chiáº¿u ngÆ°á»£c:
    # X = (u - cx) * Z / fx
    # Y = (v - cy) * Z / fy
    # Z = Z
    
    # Hoáº·c dÃ¹ng ma tráº­n K_inv:
    pixel_homog = np.array([u, v, 1])
    P_3d = Z * (K_inv @ pixel_homog)
    
    X, Y, Z_coord = P_3d
    
    print(f"â€¢ Äiá»ƒm {idx + 1} táº¡i pixel ({int(u)}, {int(v)}):")
    print(f"  X = {X:.3f} m")
    print(f"  Y = {Y:.3f} m")
    print(f"  Z = {Z_coord:.3f} m")
    print(f"  Khoáº£ng cÃ¡ch tá»« camera: {np.linalg.norm(P_3d):.3f} m\n")
    
    results_3d.append({
        'pixel_u': int(u),
        'pixel_v': int(v),
        'X': X,
        'Y': Y,
        'Z': Z_coord,
        'distance': np.linalg.norm(P_3d)
    })

# ====== 8. LÆ°u káº¿t quáº£ ======
import pandas as pd
df_output = pd.DataFrame(results_3d)
output_csv = "../../data/output/3d/3d_coords.csv"
os.makedirs(os.path.dirname(output_csv), exist_ok=True)
df_output.to_csv(output_csv, index=False)
print(f"âœ… ÄÃ£ lÆ°u káº¿t quáº£ vÃ o: {output_csv}")

# ====== 9. Visualize ======
plt.figure(figsize=(15, 5))

# áº¢nh gá»‘c vá»›i Ä‘iá»ƒm Ä‘Ã¡nh dáº¥u
plt.subplot(1, 3, 1)
plt.title("áº¢nh gá»‘c vá»›i Ä‘iá»ƒm chuáº©n")
plt.imshow(img_rgb)
plt.plot(reference_u, reference_v, 'bo', markersize=10, label=f"Ref ({Z_true_m}m)")
for idx, (u, v) in enumerate(points_uv):
    plt.plot(u, v, 'ro', markersize=8)
    plt.text(u+20, v-20, f"P{idx+1}", color='red', fontsize=10, fontweight='bold')
plt.legend()
plt.axis("off")

# Báº£n Ä‘á»“ depth
plt.subplot(1, 3, 2)
plt.title("Depth Map (mÃ©t)")
plt.imshow(depth_real, cmap='viridis')
plt.colorbar(label="Äá»™ sÃ¢u (m)")
plt.plot(reference_u, reference_v, 'bo', markersize=10)
for (u, v) in points_uv:
    plt.plot(u, v, 'ro', markersize=8)
plt.axis("off")

# Biá»ƒu Ä‘á»“ 3D scatter
ax = plt.subplot(1, 3, 3, projection='3d')
ax.set_title("Tá»a Ä‘á»™ 3D (há»‡ camera)")
ax.set_xlabel("X (m)")
ax.set_ylabel("Y (m)")
ax.set_zlabel("Z (m)")

for idx, result in enumerate(results_3d):
    ax.scatter(result['X'], result['Y'], result['Z'], 
               c='red', s=100, marker='o', label=f"P{idx+1}")

# Camera táº¡i gá»‘c tá»a Ä‘á»™
ax.scatter(0, 0, 0, c='blue', s=200, marker='^', label='Camera')
ax.legend()

plt.tight_layout()
output_img = "../../data/output/3d/3d_coords_visualization.png"
plt.savefig(output_img, dpi=150, bbox_inches='tight')
print(f"âœ… ÄÃ£ lÆ°u visualization: {output_img}")
plt.show()

print("\n" + "="*60)
print("âœ¨ HoÃ n táº¥t!")
print("="*60)
